---
layout: post
title: SOLO-Segmenting Objects by Locations
author: hoangbm
---

In the [previous blog](/yolact), I have discussed YOLACT, a common instance segmentation architecture and 
my grudges against it and its variants. In this blog, I will introduce another architecture, which I believe a more
efficient design. This is namely *SOLO*.

Before SOLO, the authors claim that there are two main paradigms to solve instance segmentation problems, like pose 
pose estimation, `top-down` and `bottom-up`. YOLACT falls into the former group when it tries *detect-then-segment* 
approach: it relies heavily on detection result to have a satisfactory mask representation. The latter tries to assign 
an embedding vector so that post-processing step could group these pixels into the same instance easily. Frankly speaking,
I haven't figure out how the latter works, especially the classification step. Anyway, both approaches are step-wise, 
which basically mean slow performance and (maybe) poor accuracy. Nevertheless, none of this matters anyway since we have 
`SOLO` in our life.

## I. SOLO
My first impression is that this architecture is inspired a lot from `SSD`. The whole image is split into `nxn` grids, 
each is responsible for detecting mask whose center lies in this grid cell. Furthermore, its backbone also generate a 
pyramid of feature maps with different sizes, each becomes an input for prediction heads: semantic classification and
instance mask. Finally, NMS will be required to filter out highly-overlapped masks.

<p align="center">
     <img src="/image/segmentation/solo.png" alt="" align="middle">
     <div align="center">
        Architecture of SOLO
    </div>
</p>

In more detailed, its backbone outputs several feature maps of different heights and widths but the same channels (
normally 256 channels). In the first branch, we have to align these feature maps to new size `SxS`, using `pooling` or 
`interpolation`. Afterward, several `1x1` convolutions are employed to create `SxSxC` final category matrix.

In the second branch, it seems to be more direct when `1x1` convolutions are used to transform feature maps into wanted 
mask representations. Please note that there are additional 2 channels in the following figure because `CoordConv` is 
used to improve position sensitivity, which is not inherent in traditional convolutional network.

<p align="center">
     <img src="/image/segmentation/solo_head.png" alt="" align="middle">
     <div align="center">
        SOLO Head architecture.
    </div>
</p>

Regarding label assignment, this is quite similar to that of SSD. Grid (i, j) is considered as positive sample if it 
falls into the center region of the mask. In the paper, they mentioned that there are 3 positive samples on average for
each mask.