---
layout: post
title: HDFS Recovery Process
---

In the previous post, I have finished presenting the architecture of HDFS. Today, I focus more on the fault tolerance, in other words, the recovery process of HDFS. As you may know, HDFS developers assume that this platform will run on the unstable system. fault tolerance can't be ignored if you want to master Hadoop system.

# I. DataNode

## 1. States of Replica in DataNode

* Finalized: This is the cool-and-dry state of replica. In other words, replicas take this title when everything is perfect, every replica of a data block have a full content and acquires a same generation stamp. Generation stamp is a code which somehow describes the version of a replica, it only changes when a replica is created or appended. At this state, corresponding metadata in NameNode is aligned with the replica's state and data.

* Replica Being Written(RBW): This is the state of currently written part of file. During this state, replica is a little messy: metadata may not match the replica. In case of failure, HDFS will try to preserve as many bytes as possible: it is called as data durability.

* Replica Waiting to be Recovered(RWR): If RBW goes south, the replica will turn to this state. This data will be either discarded or recovered in lease recovery if client dies.

* Replica Under Recovery(RUR): This is the state of replica during lease recovery.

* Temporary: This happens when data distribution in different nodes is not uniform. In this case, we either do data rebalancing takes place or increase the replication factor. It is totally transparent to the user.

<p align="center">
 <img src="/img/hdfs/recover-f2.png" alt="" align="middle">
 <div align="center"> The reading process</div>
</p>